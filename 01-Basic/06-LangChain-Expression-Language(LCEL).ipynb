{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example: Prompt+Model+OutputParser\n",
    "\n",
    "- Author: [ChangJun Lee](https://www.linkedin.com/in/cjleeno1/)\n",
    "- Peer Review: [Erika Park](https://www.linkedin.com/in/yeonseo-park-094193198/), [Wooseok Jeong](https://github.com/jeong-wooseok)\n",
    "- Proofread : [Q0211](https://github.com/Q0211)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/06-LangChain-Expression-Language(LCEL).ipynb)\n",
    "[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/06-LangChain-Expression-Language(LCEL).ipynb)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model. To illustrate how this works, let us create a chain that asks for the capital cities of various countries.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Utilizing Prompt Templates](#utilizing-prompt-templates)\n",
    "- [Chain Creation](#chain-creation)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain ChatOpenAI API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n",
    "- [LangChain Core Output Parsers](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#)\n",
    "- [Python List Tutorial](https://docs.python.org/3.13/tutorial/datastructures.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can alternatively set ```OPENAI_API_KEY``` in ```.env``` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set ```OPENAI_API_KEY``` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Key as an Environment Variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up LangSmith tracking: https://smith.langchain.com\n",
    "from langsmith import utils\n",
    "\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Prompt Templates\n",
    "\n",
    "```PromptTemplate```\n",
    "\n",
    "- A prompt template is used to create a complete prompt string by incorporating the user's input variables.\n",
    "- Usage\n",
    "  - ```template```: A template string is a predefined format where curly braces '{}' are used to represent variables.\n",
    "\n",
    "  - ```input_variables```: The names of the variables to be inserted within the curly braces are defined as a list.\n",
    "\n",
    "```input_variables```\n",
    "\n",
    "- ```input_variables``` is a list that defines the names of the variables used in the ```PromptTemplate```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "import os\n",
    "import httpx\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_API_VERSION = os.environ.get('AZURE_OPENAI_API_VERSION')\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "AZURE_OPENAI_API_KEY = os.environ.get('AZURE_OPENAI_API_KEY')\n",
    "\n",
    "httpx_client = httpx.Client(http2=True, verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```from_template()``` method is used to create a ```PromptTemplate``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method.\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Korea?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"Korea\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of USA?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"USA\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.1,\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_version = AZURE_OPENAI_API_VERSION,\n",
    "    deployment_name = AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    openai_api_key = AZURE_OPENAI_API_KEY,\n",
    "    http_client = httpx_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Creation\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "Here, we use LCEL to combine various components into a single chain.\n",
    "\n",
    "![lcel.png](./assets/02-langchain-expression-language.png)\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "The ```|``` symbol works similarly to the [Unix pipe operator](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>), linking different components and passing the output of one component as the input to the next.\n",
    "\n",
    "In this chain, user input is passed to the prompt template, and the output from the prompt template is then forwarded to the model. By examining each component individually, you can understand what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='Please explain {topic} in simple terms.')\n",
       "| AzureChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001393C0AD450>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001393C4F81D0>, root_client=<openai.lib.azure.AzureOpenAI object at 0x000001393A830A10>, root_async_client=<openai.lib.azure.AsyncAzureOpenAI object at 0x000001393C0AE410>, model_name='gpt-4o-mini', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'), http_client=<httpx.Client object at 0x000001393A58B550>, disabled_params={'parallel_tool_calls': None}, azure_endpoint='https://pstestopenaidply-3icksnah2q6ks.openai.azure.com/', deployment_name='pstestopenaidply-3icksnah2q6ks', openai_api_version='2024-12-01-preview', openai_api_type='azure')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the prompt as a `PromptTemplate` object.\n",
    "prompt = PromptTemplate.from_template(\"Please explain {topic} in simple terms.\")\n",
    "\n",
    "\n",
    "# Combine the prompt and model into a chain\n",
    "chain = prompt | model\n",
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling ```invoke()```\n",
    "\n",
    "- Input values are provided in the form of a Python dictionary (key-value pairs).  \n",
    "- When calling the ```invoke()``` function, these input values are passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topic in the `input` dictionary to 'The Principles of Learning in Artificial Intelligence Models'.\n",
    "input = {\"topic\": \"The Principles of Learning in Artificial Intelligence Models\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The principles of learning in artificial intelligence (AI) models can be understood as the basic ideas that guide how these models learn from data and improve their performance over time. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data**: AI models learn from data. The more relevant and high-quality data they have, the better they can learn. Think of data as the \"food\" that helps the model grow and improve.\n",
      "\n",
      "2. **Patterns**: AI models look for patterns in the data. Just like humans recognize trends or similarities in experiences, AI identifies relationships and structures in the data to make predictions or decisions.\n",
      "\n",
      "3. **Feedback**: Learning often involves feedback. When an AI model makes a prediction, it can receive feedback on whether it was correct or not. This feedback helps the model adjust and improve its future predictions.\n",
      "\n",
      "4. **Generalization**: A good AI model should not just memorize the data it was trained on but should also be able to apply what it learned to new, unseen data. This ability to generalize is crucial for the model to be useful in real-world situations.\n",
      "\n",
      "5. **Iteration**: Learning is an iterative process. AI models often go through many cycles of training, testing, and refining. Each cycle helps the model get better at understanding the data and making accurate predictions.\n",
      "\n",
      "6. **Complexity**: Some problems are more complex than others. AI models can vary in complexity, from simple rules to advanced neural networks. The choice of model depends on the problem and the data available.\n",
      "\n",
      "7. **Overfitting and Underfitting**: These are common issues in AI learning. Overfitting happens when a model learns the training data too well, including noise, and performs poorly on new data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data. The goal is to find a balance.\n",
      "\n",
      "8. **Transfer Learning**: Sometimes, models can benefit from knowledge gained in one task and apply it to another related task. This is called transfer learning and helps save time and resources.\n",
      "\n",
      "9. **Continuous Learning**: AI models can continue to learn and adapt over time as they are exposed to new data. This ability to learn continuously helps them stay relevant and accurate.\n",
      "\n",
      "In summary, the principles of learning in AI models revolve around using data to find patterns, receiving feedback, generalizing knowledge, iterating on learning processes, managing complexity, and adapting over time. These principles help AI systems become more effective and reliable in performing tasks."
     ]
    }
   ],
   "source": [
    "# Connect the `prompt` object and the `model` object using the pipe (`|`) operator.\n",
    "# Use the `invoke` method to pass the `input`.\n",
    "# This will return the message generated by the AI model.\n",
    "result = chain.invoke(input)\n",
    "print(result.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of outputting a streaming response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can do.\n",
      "\n",
      "2. **Learning from Examples**: AI models learn by looking at examples. For instance, if you show an AI many pictures of cats and dogs, it can learn to tell the difference between them. This is similar to how humans learn by observing and practicing.\n",
      "\n",
      "3. **Feedback Loop**: AI models improve through feedback. When they make mistakes, they can adjust their understanding based on the corrections. This is like a teacher giving feedback to a student to help them learn from their errors.\n",
      "\n",
      "4. **Generalization**: AI models aim to generalize from the examples they see. This means they should be able to apply what they've learned to new, unseen data. For example, if an AI learns to recognize cats from specific pictures, it should still recognize a cat it has never seen before.\n",
      "\n",
      "5. **Optimization**: AI models often use optimization techniques to improve their performance. This involves tweaking their internal settings to minimize errors. It’s like fine-tuning a musical instrument to get the best sound.\n",
      "\n",
      "6. **Adaptability**: Good AI models can adapt to new information. If the environment changes or new data comes in, they can adjust their learning accordingly. This is similar to how people learn to adapt to new situations.\n",
      "\n",
      "7. **Scalability**: AI models should be able to handle increasing amounts of data without losing performance. This means they can learn from more examples as they become available, much like how a student can learn more as they read more books.\n",
      "\n",
      "8. **Transfer Learning**: Sometimes, knowledge gained from one task can help with another task. For example, if an AI learns to recognize animals, it might use that knowledge to help recognize different types of objects. This is like how learning to ride a bike can help you learn to ride a motorcycle.\n",
      "\n",
      "9. **Exploration vs. Exploitation**: AI models need to balance exploring new possibilities (trying new things) and exploiting what they already know (using what works well). This is similar to how a person might try new foods while still enjoying their favorite dishes.\n",
      "\n",
      "These principles help guide the development and training of AI models, making them more effective and efficient in learning from data and performing tasks."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "An **Output Parser** is a tool designed to transform or process the responses from an AI model into a specific format. Since the model's output is typically provided as free-form text, an **Output Parser** is essential to convert it into a structured format or extract the required data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = (\n",
    "    StrOutputParser()\n",
    ")  # Directly returns the model's response as a string without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An output parser is added to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A processing chain is constructed by connecting the prompt, model, and output parser.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\\n\\n1. **Data is Key**: AI models learn from data. The more high-quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can prepare.\\n\\n2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you want an AI to recognize cats in pictures, you show it many pictures of cats and non-cats. Over time, it learns to identify the features that make a cat a cat.\\n\\n3. **Feedback Loop**: AI models improve through feedback. When they make a mistake, they receive feedback (like a teacher correcting a student), which helps them adjust and do better next time. This is often done through a process called \"training.\"\\n\\n4. **Generalization**: A good AI model can apply what it has learned to new, unseen data. This means it doesn’t just memorize the examples it was trained on but understands the underlying patterns. For example, if it learns what a cat looks like from various pictures, it should be able to recognize a new cat it hasn’t seen before.\\n\\n5. **Adaptability**: AI models can adapt to new information. If the environment changes or new data becomes available, a well-designed AI can update its knowledge and improve its performance accordingly.\\n\\n6. **Optimization**: AI models aim to minimize errors and maximize accuracy. They use mathematical techniques to find the best way to make predictions or decisions based on the data they have.\\n\\n7. **Complexity Management**: AI models can be simple or complex, depending on the task. Sometimes, a simple model works just as well as a complex one. The key is to find the right balance between simplicity and performance.\\n\\n8. **Transfer Learning**: This principle allows an AI model to apply knowledge gained from one task to a different but related task. For example, if an AI learns to recognize dogs, it might use some of that knowledge to help it recognize wolves.\\n\\n9. **Continuous Learning**: Some AI models can keep learning even after their initial training. This means they can improve over time as they encounter more data or new situations, similar to how people keep learning throughout their lives.\\n\\nIn summary, the principles of learning in AI models revolve around using data effectively, learning from examples, receiving feedback, generalizing knowledge, adapting to new information, optimizing performance, managing complexity, transferring knowledge, and continuing to learn over time. These principles help AI systems become more intelligent and useful in various applications.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the invoke method of the chain object to pass the input\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The principles of learning in artificial intelligence (AI) models can be understood through a few key concepts. Here’s a simple breakdown:\n",
      "\n",
      "1. **Data**: AI models learn from data. Just like humans learn from experiences, AI systems learn from examples. The more relevant data they have, the better they can learn.\n",
      "\n",
      "2. **Training**: This is the process where the AI model is exposed to data. During training, the model tries to understand patterns and relationships in the data. It adjusts its internal settings (called parameters) to improve its predictions or decisions.\n",
      "\n",
      "3. **Feedback**: After making predictions, the model receives feedback on how well it did. This feedback helps the model learn from its mistakes. For example, if it predicts something incorrectly, it adjusts its parameters to avoid making the same mistake in the future.\n",
      "\n",
      "4. **Generalization**: The goal of an AI model is not just to memorize the training data but to generalize. This means it should be able to make accurate predictions on new, unseen data. Good models learn to recognize patterns that apply broadly, rather than just specific examples.\n",
      "\n",
      "5. **Overfitting and Underfitting**:\n",
      "   - **Overfitting**: This happens when a model learns the training data too well, including the noise and outliers. It performs well on training data but poorly on new data.\n",
      "   - **Underfitting**: This occurs when a model is too simple to capture the underlying patterns in the data. It performs poorly on both training and new data.\n",
      "\n",
      "6. **Algorithms**: Different algorithms (methods) are used to train AI models. Some common ones include decision trees, neural networks, and support vector machines. Each has its strengths and weaknesses depending on the type of data and the problem being solved.\n",
      "\n",
      "7. **Iteration**: Learning is often an iterative process. The model is trained, evaluated, and then improved repeatedly. This cycle continues until the model reaches a satisfactory level of performance.\n",
      "\n",
      "8. **Evaluation**: After training, the model is tested on a separate set of data (called validation or test data) to see how well it performs. This helps ensure that it can generalize to new situations.\n",
      "\n",
      "In summary, AI models learn by processing data, receiving feedback, and adjusting their internal settings to improve their predictions. The goal is to find a balance between learning enough to make accurate predictions while avoiding memorizing the training data too closely."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying and Modifying Templates\n",
    "\n",
    "- The prompt content below can be **modified** as needed for testing purposes.  \n",
    "- The ```model_name``` can also be adjusted for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue: \n",
    "\"\"\"\n",
    "\n",
    "# Generate the prompt using the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.1,\n",
    "    azure_endpoint = AZURE_OPENAI_ENDPOINT,\n",
    "    openai_api_version = AZURE_OPENAI_API_VERSION,\n",
    "    deployment_name = AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    openai_api_key = AZURE_OPENAI_API_KEY,\n",
    "    http_client = httpx_client,\n",
    ")\n",
    "\n",
    "# Initialize the ChatOpenAI model.\n",
    "# model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the string output parser.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the chain.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Customer:** Hi there! Could I see the menu, please?  \n",
      "**Waiter:** Of course! Here you go. Do you have any questions about the menu?  \n",
      "**Customer:** Yes, I’m curious about the pasta dishes. Which one do you recommend?  \n",
      "**Waiter:** Our spaghetti carbonara is very popular. It’s made with fresh ingredients and has a creamy sauce.  \n",
      "**Customer:** That sounds delicious! I’ll have the spaghetti carbonara, please. And can I get a side salad with that?  \n",
      "**Waiter:** Absolutely! Would you like any dressing for your salad?  \n",
      "**Customer:** Yes, I’d like balsamic vinaigrette, please.  \n",
      "**Waiter:** Great choice! Would you like anything to drink?  \n",
      "**Customer:** Just water, please.  \n",
      "**Waiter:** Perfect! I’ll get that order in for you right away.  \n",
      "**Customer:** Thank you!\n",
      "\n",
      "- Explanation of the Dialogue: \n",
      "In this conversation, the customer initiates the interaction by asking for the menu, which is a common first step when dining out. The waiter responds politely and offers assistance with any questions. The customer expresses interest in a specific category of food (pasta) and asks for a recommendation, which is a typical way to engage with the waiter and get suggestions. The waiter recommends a popular dish, and the customer decides to order it along with a side salad, demonstrating how to customize an order. The waiter then checks if the customer wants dressing for the salad and offers a drink option, which is standard practice in restaurants. The conversation concludes with the customer thanking the waiter, showcasing polite communication. This dialogue is suitable for learners to practice ordering food in a restaurant setting.\n"
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response.\n",
    "print(chain.invoke({\"question\": \"I want to go to a restaurant and order food.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:  \n",
      "**Customer:** Hi there! Could I see the menu, please?  \n",
      "**Waiter:** Of course! Here you go. Do you have any questions about the menu?  \n",
      "**Customer:** Yes, I’m curious about the pasta dishes. Which one do you recommend?  \n",
      "**Waiter:** Our spaghetti carbonara is very popular. It’s made with fresh ingredients and has a creamy sauce.  \n",
      "**Customer:** That sounds delicious! I’ll have the spaghetti carbonara, please. Can I also get a side salad?  \n",
      "**Waiter:** Absolutely! Would you like any dressing with your salad?  \n",
      "**Customer:** Yes, please. I’d like balsamic vinaigrette.  \n",
      "**Waiter:** Great choice! Would you like anything to drink?  \n",
      "**Customer:** Just water, please.  \n",
      "**Waiter:** Perfect! I’ll get that order in for you right away.  \n",
      "**Customer:** Thank you!  \n",
      "\n",
      "- Explanation of the Dialogue:  \n",
      "In this conversation, the customer initiates the interaction by asking for the menu, indicating their desire to order food. The waiter responds politely and offers assistance, creating a welcoming atmosphere. The customer expresses interest in a specific type of dish (pasta) and seeks a recommendation, which shows engagement with the menu. The waiter suggests a popular dish, demonstrating knowledge of the restaurant's offerings. The customer then places their order, including a side item and a drink, which is a common practice in restaurant settings. The waiter confirms the order and assures the customer that it will be taken care of, ending the interaction on a positive note. This dialogue exemplifies typical restaurant etiquette and communication."
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response\n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"I want to go to a restaurant and order food.\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "\n",
      "**Customer:** Hi there! I’d like to order a pizza, please.\n",
      "\n",
      "**Pizza Server:** Of course! What size would you like? We have small, medium, large, and extra-large.\n",
      "\n",
      "**Customer:** I’ll take a large, please. \n",
      "\n",
      "**Pizza Server:** Great choice! What type of pizza do you want? We have pepperoni, cheese, veggie, and a few specialty pizzas.\n",
      "\n",
      "**Customer:** I’ll go with pepperoni. Can I add extra cheese?\n",
      "\n",
      "**Pizza Server:** Absolutely! Extra cheese on a large pepperoni pizza. Would you like anything else? \n",
      "\n",
      "**Customer:** Yes, can I also get a side of garlic bread and a two-liter soda?\n",
      "\n",
      "**Pizza Server:** Sure! We have a few soda options. We have cola, diet cola, lemon-lime, and root beer. Which one would you like?\n",
      "\n",
      "**Customer:** I’ll take a cola, please.\n",
      "\n",
      "**Pizza Server:** Great! So that’s one large pepperoni pizza with extra cheese, a side of garlic bread, and a cola. Would you like to add any dipping sauces?\n",
      "\n",
      "**Customer:** Yes, please! Can I get a marinara sauce and a ranch dressing?\n",
      "\n",
      "**Pizza Server:** Absolutely! Your total comes to $25.99. How would you like to pay?\n",
      "\n",
      "**Customer:** I’ll pay with my credit card.\n",
      "\n",
      "**Pizza Server:** Perfect! I’ll take that and have your order ready in about 30 minutes.\n",
      "\n",
      "**Customer:** Thank you! I appreciate it.\n",
      "\n",
      "**Pizza Server:** You’re welcome! Enjoy your meal!\n",
      "\n",
      "---\n",
      "\n",
      "- Explanation of the Dialogue: \n",
      "\n",
      "This dialogue captures a typical conversation when ordering pizza in the US. It begins with the customer greeting the server and expressing their intention to place an order. The server asks about the size of the pizza, which is a common initial query. The customer specifies they want a large pepperoni pizza and adds a request for extra cheese, demonstrating how customers can customize their orders.\n",
      "\n",
      "The server continues by offering additional items, like garlic bread and soda, which reflects the common practice of upselling in food service. The server also provides options for the soda, showcasing the variety available. The customer selects their preferences and further adds dipping sauces, which is a popular choice when ordering pizza.\n",
      "\n",
      "Finally, the server confirms the order and provides the total cost, with the customer choosing to pay by credit card, a common payment method. The exchange ends on a polite note, with both parties expressing gratitude, which is typical in customer service interactions. This dialogue is a practical example of everyday communication in a restaurant setting, highlighting key phrases and vocabulary related to food ordering."
     ]
    }
   ],
   "source": [
    "# This time, set the question to 'Ordering Pizza in the US' and execute it.\n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"Ordering Pizza in the US\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-unqt6ecX-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
